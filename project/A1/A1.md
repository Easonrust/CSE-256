# Assignment 1: Text Classification

## 2 Improve the Basic Classifier

### 2.1 Guided Feature Engineering

In this section I swap out the basic CountVectorizer withTFidfVectorizer. The parameter $n$ of TFidfVectorizer is the maximum n-gram feature length.   I use the LogisticRegression classifier to perform the classification task. The paramenter $C$ of LogisticRegression is the Inverse of regularization length. I do experiments on n range from 1 to 3, and on each $n$ I use the $C$ range from 1 to 10. The results of accurcy on the train set and dev set are as belows:

| C                         | 1     | 2     | 3     | 4     | 5     | 6     | 7     | 8     | 9     | 10    |
| ------------------------- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- |
| Accurcy on Train when n=1 | 0.902 | 0.928 | 0.945 | 0.956 | 0.962 | 0.968 | 0.974 | 0.978 | 0.982 | 0.985 |
| Accurcy on Dev when n=1   | 0.766 | 0.766 | 0.777 | 0.790 | 0.795 | 0.795 | 0.793 | 0.788 | 0.788 | 0.790 |


| C                         | 1     | 2     | 3     | 4     | 5     | 6     | 7     | 8     | 9     | 10    |
| ------------------------- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- |
| Accurcy on Train when n=2 | 0.957 | 0.982 | 0.991 | 0.996 | 0.998 | 0.999 | 0.999 | 1.000 | 1.000 | 1.000 |
| Accurcy on Dev when n=2   | 0.771 | 0.782 | 0.777 | 0.784 | 0.782 | 0.782 | 0.782 | 0.784 | 0.784 | 0.788 |

| C                         | 1     | 2     | 3     | 4     | 5     | 6     | 7     | 8     | 9     | 10    |
| ------------------------- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- |
| Accurcy on Train when n=3 | 0.980 | 0.995 | 0.998 | 1.000 | 1.000 | 1.000 | 1.000 | 1.000 | 1.000 | 1.000 |
| Dev                       | 0.771 | 0.779 | 0.782 | 0.790 | 0.788 | 0.790 | 0.790 | 0.790 | 0.788 | 0.790 |

| C     | 1     | 2     | 3     | 4     | 5     | 6     | 7     | 8     | 9     | 10    |
| ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- |
| Train | 0.991 | 0.998 | 1.000 | 1.000 | 1.000 | 1.000 | 1.000 | 1.000 | 1.000 | 1.000 |
| Dev   | 0.762 | 0.769 | 0.775 | 0.775 | 0.777 | 0.777 | 0.779 | 0.779 | 0.784 | 0.784 |

From the table I can see that when $n=1$, the accuracy is better than others. So I draw the graph of accuracy and $C$ to analyze the result.
![download](https://tva1.sinaimg.cn/large/e6c9d24egy1h13240yktyj20b907qt91.jpg)

From the results above I can see that when $n=1$, $C=5$, the accuracy on the dev set is at **0.795**. Compared to the base line, whose accuracy on dev set is **0.777**. Therefore, the improvement is **2.3%**.

From the results above I can also see that when $n$ become bigger, the model will over-fit where the accuracy on the train set is extremely high, but the accuracy on the test set is relatively low.

### 2.2 Independent Feature Engineering

In this section, I make changes to the TFidfVectorizer to do feature engineering. The changes I make are primaritily on the tokenization method. I change the stop_words(default value is None) and token_pattern(default value is r”(?u)\b\w\w+\b”) which are two parameters of the TFidfVectorizer. 

For stop_words, Some words (e.g. “the”, “a”, “is” in English) are presumed to be uninformative in representing the content of a text, therefore I should remove them to avoid them distracting our classification task. Here I set the stop words list to ["and","the","am","is","are","a","an"].

For token_pattern, the default value is r”(?u)\b\w\w+\b”) which include 2 or more alphanumeric characters. Here we remove numbers from the tokens to use r"(?u)\b[A-Za-z]\[A-Za-z\]+\b" to include 2 or more alphabetic characters

Based on the results from 2.1, I do experiments on $n=1$. I do three kinds of experiments:

1. only change stop_words
	| C                | 1     | 2     | 3     | 4     | 5     | 6     | 7     | 8     | 9     | 10    |
	| ---------------- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- |
	| Accurcy on Train | 0.899 | 0.926 | 0.942 | 0.952 | 0.962 | 0.967 | 0.972 | 0.978 | 0.982 | 0.985 |
	| Accurcy on Dev   | 0.762 | 0.769 | 0.779 | 0.784 | 0.786 | 0.786 | 0.783 | 0.782 | 0.782 | 0.782 |
1. only change token_pattern
	| C                | 1     | 2     | 3     | 4     | 5     | 6     | 7     | 8     | 9     | 10    |
	| ---------------- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- |
	| Accurcy on Train | 0.902 | 0.928 | 0.944 | 0.957 | 0.963 | 0.971 | 0.975 | 0.979 | 0.982 | 0.985 |
	| Accurcy on Dev   | 0.764 | 0.771 | 0.782 | 0.786 | 0.795 | 0.797 | 0.797 | 0.799 | 0.799 | 0.799 |
1. Change both stop_words and token_pattern
	| C                | 1     | 2     | 3     | 4     | 5     | 6     | 7     | 8     | 9     | 10    |
	| ---------------- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- |
	| Accurcy on Train | 0.900 | 0.925 | 0.943 | 0.955 | 0.962 | 0.969 | 0.974 | 0.978 | 0.981 | 0.984 |
	| Accurcy on Dev   | 0.764 | 0.766 | 0.769 | 0.779 | 0.784 | 0.790 | 0.790 | 0.790 | 0.788 | 0.788 |

From the results above we can find that the three experiments are all better than the baseline. The best of them on dev set is **0.799** when we only use the stop_words, at $n$=1 $C$=8 which improve **2.8%** from the baseline.  the graph of accuracy and $C$ when we only use stop_words is as below:

![download](https://tva1.sinaimg.cn/large/e6c9d24egy1h13ckrltkzj20b907qt91.jpg)



I think the performance is better when we only use stop_words, because the words in the ["and","the","am","is","are","a","an"] are truly uninformative in representing the content of a text. But when I change the token_pattern, I only remove the numbers in the tokens, which is too general, however this text classification task require a more custom solution.
